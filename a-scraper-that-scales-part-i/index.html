<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: January 5, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.f76b0c056129906c3efa1ca1d91f2d31.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/pygments.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/pygments.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  


























  
  
  






  <meta name="author" content="Rohail Taimour" />





  

<meta name="description" content="Explore the journey of building a robust web scraper for analyzing Belgium&#39;s property market. Learn how we transitioned from Selenium to Beautiful Soup for efficiency, used Poetry and Typer for better dependency management, amongst other tools. This blog is part one of a series aimed at creating a scalable data collection and analysis tool" />



<link rel="alternate" hreflang="en-us" href="https://www.rohailtaimour.com/a-scraper-that-scales-part-i/" />
<link rel="canonical" href="https://www.rohailtaimour.com/a-scraper-that-scales-part-i/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />
<meta property="twitter:image" content="https://www.rohailtaimour.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png" />
<meta property="og:site_name" content="Musings from Rohail" />
<meta property="og:url" content="https://www.rohailtaimour.com/a-scraper-that-scales-part-i/" />
<meta property="og:title" content="Part I: The Motivation to Build a Scraper in Python | Musings from Rohail" />
<meta property="og:description" content="Explore the journey of building a robust web scraper for analyzing Belgium&#39;s property market. Learn how we transitioned from Selenium to Beautiful Soup for efficiency, used Poetry and Typer for better dependency management, amongst other tools. This blog is part one of a series aimed at creating a scalable data collection and analysis tool" /><meta property="og:image" content="https://www.rohailtaimour.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-10-24T16:14:00&#43;02:00"
    />
  
  
    <meta property="article:modified_time" content="2023-10-24T16:14:00&#43;02:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.rohailtaimour.com/a-scraper-that-scales-part-i/"
  },
  "headline": "Part I: The Motivation to Build a Scraper in Python",
  
  "datePublished": "2023-10-24T16:14:00+02:00",
  "dateModified": "2023-10-24T16:14:00+02:00",
  
  "author": {
    "@type": "Person",
    "name": "Rohail Taimour"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Sigma Graph Inc",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.rohailtaimour.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Explore the journey of building a robust web scraper for analyzing Belgium's property market. Learn how we transitioned from Selenium to Beautiful Soup for efficiency, used Poetry and Typer for better dependency management, amongst other tools. This blog is part one of a series aimed at creating a scalable data collection and analysis tool"
}
</script>

  

  




  
  
  

  
  

  
  
  
  
  
    <script src="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.js" integrity="sha512-yXXqOFjdjHNH1GND+1EO0jbvvebABpzGKD66djnUfiKlYME5HGMUJHoCaeE4D5PTG2YsSJf6dwqyUUvQvS0vaA==" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.css" integrity="sha512-LQ97camar/lOliT/MqjcQs5kWgy6Qz/cCRzzRzUCfv0fotsCTC9ZHXaPQmJV8Xu/PVALfJZ7BDezl5lW3/qBxg==" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#1565c0",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#1565c0"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://www.cookiesandyou.com"
      }
    })});
  </script>



  
  <title>Part I: The Motivation to Build a Scraper in Python | Musings from Rohail</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="5b49bc16d699569b9faaa7c1093cee21" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Musings from Rohail</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Musings from Rohail</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/post/"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
              
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/markdown-cv" target="_blank" rel="noopener"><span>Resume</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/sitemap/"><span>Sitemap</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/contact/"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    
      
      
      <div class="article-container py-1" style="background: initial">
        
  <nav class="d-none d-md-flex" aria-label="breadcrumb">
    <ol class="breadcrumb">
      
  
    
  
    
  
    
  

    <li class="breadcrumb-item">
      <a href="/">
        
          Home
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/post/">
        
          Posts
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/post/series-building-a-scraper-that-scales/">
        
          Building a scraper that scales
        
      </a>
    </li>
  

      <li class="breadcrumb-item active" aria-current="page">
        Part I: The Motivation to Build a Scraper in Python
      </li>
    </ol>
  </nav>




      </div>
    

    <article class="article">
  













  

  
  
  
<div class="article-container pt-3">
  <h1>Part I: The Motivation to Build a Scraper in Python</h1>

  

  
    


<div class="article-metadata">

  
  <span class="article-series">
    Series:
    
    
    <a href="/series/building-a-scraper-that-scales">Building a Scraper that scales</a>
    
  </span>
  <span class="middot-divider"></span>
  

  
  
  
  
  <div>
    

  
  </div>
  
  

  
  <span class="article-date">
    
    
    
    
    Oct 24, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/technology/">technology</a></span>
  

</div>
    





  
</div>



  <div class="container-fluid">
    <div class="row flex-xl-nowrap">
      
      
      <div class="d-none d-xl-block col-xl-2 docs-toc">
        
<div class="docs-toc">
  












  <ul class="nav toc-top">
    <li>
      <a href="#" id="back_to_top" class="docs-toc-title">Contents</a>
    </li>
  </ul>

  <nav id="TableOfContents">
  <ul>
    <li><a href="#motivation">Motivation</a></li>
    <li><a href="#implementing-the-proof-of-concept">Implementing the Proof of concept</a></li>
    <li><a href="#a-sidenote-on-bayesian-statistics">A sidenote on Bayesian statistics</a></li>
    <li><a href="#revisiting-the-implementation-once-again">Revisiting the implementation once again</a></li>
    <li><a href="#areas-of-improvement">Areas of improvement</a>
      <ul>
        <li><a href="#1-efficiency-in-data-scraping">1. Efficiency in Data Scraping</a></li>
        <li><a href="#2-dependency-management">2. Dependency Management</a></li>
        <li><a href="#3-code-refactoring-for-readability-and-maintainability">3. Code Refactoring for Readability and Maintainability</a></li>
        <li><a href="#5-data-storage-and-validation">5. Data Storage and Validation</a></li>
      </ul>
    </li>
    <li><a href="#final-comments">Final comments</a></li>
  </ul>
</nav>
  











</div>

      </div>
      

      
      <main
        class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content"
        role="main">
        <div class="article-container">
          <div class="article-style">
            
<p>
  This post is part of the
  <a href="https://www.rohailtaimour.com/series/building-a-scraper-that-scales/" style="font-weight: bold">Building a Scraper that scales</a>
  series.
</p>


<ol><li><b>Part I: The Motivation to Build a Scraper in Python</b></li></ol>
            <h2 id="motivation">Motivation</h2>
<p>Remember that period when most parts of the world were in a lockdown due to
COVID? Yes, we&rsquo;re nearing the end of 2023 and COVID seems like a distant memory
at this point. However, like I imagine many of us, I suddenly found that being
restricted in movement and social interaction to a large extent, I had a lot
more time at my disposal. This was also a time where my wife and I realised that
we could have more space for ourselves so each of us could have an office setup
we could be happy with. This also being a time of low interest rates to
encourage consumption in the economy, it was an especially interesting property
market.</p>
<p>This seemed as good a time as any to write a scraper for Belgium&rsquo;s most popular
property listings website: <a href="https://immoweb.be" target="_blank" rel="noopener">immoweb</a>. My desire for this
first version was to first, be able to have a very general idea of the Brussels
property market. Thereafter, I would launch this script every few days to look
at the new properties. The output of this script would be a CSV that I&rsquo;d use to
spot good deals and have all the relevant information I&rsquo;d need to schedule
visits.</p>
<h2 id="implementing-the-proof-of-concept">Implementing the Proof of concept</h2>
<p>I was running this script from a windows machine at the time and having done a
scraping project once before already, knew that I&rsquo;d start with <code>selenium</code> for
the browser automation and parsing of the html. The setup required that I choose
a browser and a corresponding geckodriver (with the appropriate version for your
browser) to go along with it. I&rsquo;ve used firefox and edge browsers (and their
respective drivers) for different iterations of the scraper implementation.</p>
<p>After messing around with developer tools, looking into the dom&rsquo;s containing the
information I was looking for using <code>inspect</code>, I had a script that was doing the
job. I made a conda export of the environment I used for the scraping in case I
ever needed to revisit this work again. This script did the job and I was quite
happy leaving it at that with an environment export so I could pick up from this
analysis when needed. This version of the script can be found
<a href="https://github.com/roumail/immoweb-scraper/tree/second_run" target="_blank" rel="noopener">here</a> for those who
are interested.</p>
<h2 id="a-sidenote-on-bayesian-statistics">A sidenote on Bayesian statistics</h2>
<p>For the longest time I&rsquo;ve been a fan of Bayesian statistics. Being able to
explicitly encode your modelling assumptions in the form of priors, as well as
being very deliberate in reconstructing the data generating process of the
phenomenon you&rsquo;re modelling. You can visually verify how well your model is
generalizing by doing what is called a
<a href="https://en.wikipedia.org/wiki/Posterior_predictive_distribution" target="_blank" rel="noopener">posterior predictive check</a>.
The computational aspects of MCMC sampling also appeals to the nerd in me, while
the convergence of your sampler gives indications about how well-informed a
hypothesis you have for your data generating process. An ill-formulated model
will simply not converge, unlike a number of other approaches which would always
give a solution and then you&rsquo;re left to figure out if you&rsquo;re overfitting or
underfitting. Then there is the fact that you are always able to work with
distributions of your phenomenon of interest rather than relying solely on point
estimates like we would in most other methods. There&rsquo;s a number of fascinating
things that are possible with these posterior distributions, which include
bayesian decision making. I will link to a great discussion on the subject by
Thomas Wiecki on the subject
<a href="https://twiecki.io/blog/2019/01/14/supply_chain/" target="_blank" rel="noopener">here</a> where we can see how to
use our models to directly show the impact of uncertainy on real business
metrics rather than arcane statistical metrics such as <code>mean squared error</code>,
<code>f1 score</code> and the like which don&rsquo;t hold any real business meaning.</p>
<p>Naturally, I have my bias for these methods and using these models bring their
own challenges. In some cases, traditional machine learning approaches would
give better performance without sacrificing interpretability and help you reach
a conclusion faster than using these bespoke modelling approaches. Nonetheless,
I was on the lookout for an opportunity to find a dataset where I could exploit
the natural hierarchical structure of data in a
<a href="https://en.wikipedia.org/wiki/Bayesian_hierarchical_modeling" target="_blank" rel="noopener">hierarchical modelling</a>
or the flexiblity of Gaussian process modelling to capture the intricaties of
non-linear processes. The
<a href="https://www.pymc.io/projects/examples/en/latest/gaussian_processes/GP-smoothing.html" target="_blank" rel="noopener">link</a>
shows the distinction between modelling the same problem as a regression vs
using a gaussian process smoothing model.</p>
<h2 id="revisiting-the-implementation-once-again">Revisiting the implementation once again</h2>
<p>Any data scientist or machine learning practitioner will tell you about their
struggles with data. It&rsquo;s either data quality (or lack thereof) or just the lack
of data itself for performing interesting analyses. Then it suddenly occurred to
me: property data is perfect for the experiments I wanted to conduct.</p>
<p>Scraping property prices over time gives the opportunity to model property
prices over time and ask interesting questions, including, but not limited to
the following:</p>
<ul>
<li>Are rental property prices growing at the same rate as purchase properties?</li>
<li>Do we observe a similar growth rate across different communes?</li>
<li>Are properties in the same commune priced similarly and if so, how much does
this vary by commune?</li>
<li>What are the most important determinants of price?</li>
</ul>
<p>A dataset of this nature contains elements of time series analysis since
property prices evolve over time. There is also a natural structure in the data
that can be exploited since we can indeed expect properties within communes to
be similarly priced. This would be a place where we can use Gaussian process
modelling to capture the underlying trends and fluctuations in property prices
within each commune. We can use property proximity to model the inherent spatial
relationships between properties, assuming that properties closer to each other
are more likely to have similar prices!</p>
<p>By revisiting my initial scraper implementation with this newfound focus, I am
not just enhancing a tool; I am building a robust data collection pipeline that
will serve as the backbone for these sophisticated analytical experiments.</p>
<h2 id="areas-of-improvement">Areas of improvement</h2>
<p>With a clear goal in mind, I identified several key areas to refine the
scraper&rsquo;s implementation. These improvements were aimed at making the scraper
more efficient, easier to manage, and more robust for data collection and
analysis.</p>
<h3 id="1-efficiency-in-data-scraping">1. Efficiency in Data Scraping</h3>
<p>Switch to Beautiful Soup: I wanted to transition from
<a href="https://pypi.org/project/selenium/" target="_blank" rel="noopener">Selenium</a> to
<a href="https://pypi.org/project/beautifulsoup4/" target="_blank" rel="noopener">Beautiful Soup</a> for parsing raw HTML.
This change ought to significantly reduced the time needed to scrape data.</p>
<p>Parametrization of Postal Codes: Allowing postal codes as an input parameter to
make the scraper more flexible. I was initially only looking into a few communes
in Brussels that I was interested in. However, if I wanted to do some
interesting analyses, I also wanted to consider communes neighboring Brussels.</p>
<h3 id="2-dependency-management">2. Dependency Management</h3>
<p>Use of Poetry: To manage the project&rsquo;s dependencies more effectively, I wanted
to convert the script into a Python package and used <a href="">Poetry</a> for managing the
dependencies. This streamlines the installation process and allows me to manage
the package versions in a systematic version. This would be especially useful as
we dockerize the analysis in the future and build a CI/CD pipeline.</p>
<p>Implementation of Typer: I used <a href="https://pypi.org/project/typer/" target="_blank" rel="noopener">Typer</a> to
create a command-line interface from the main application entrypoint. I&rsquo;ve
effectively transitioned to using this instead of
<a href="https://pypi.org/project/click/" target="_blank" rel="noopener"><code>click</code></a> recently.</p>
<h3 id="3-code-refactoring-for-readability-and-maintainability">3. Code Refactoring for Readability and Maintainability</h3>
<p>Object-Oriented Approach: I wanted to refactor the code to use Python classes
instead of just functions where appropriate. By using meaningful class names,
the code can become self-documenting and easier to maintain and extend in the
long run.</p>
<h3 id="5-data-storage-and-validation">5. Data Storage and Validation</h3>
<p>SQLite Database: I wanted to use a SQLite database with an initial schema to
store the data I&rsquo;d be accumulating over time. I&rsquo;ve really enjoyed working with
<a href="https://pypi.org/project/SQLAlchemy/" target="_blank" rel="noopener"><code>SQLAlchemy</code></a> as the ORM mapper to
interact with the database.</p>
<p>Data Validation with Pydantic: Before adding the scraped data to the database, I
implemented validation checks using
<a href="https://pypi.org/project/pydantic/" target="_blank" rel="noopener">Pydantic</a>. This ensured that only
high-quality, accurate data was stored.</p>
<p>By focusing on these areas, I aimed to build a scraper that was not just a
one-off script but a robust data collection tool capable of supporting more
complex analyses and experiments.</p>
<h2 id="final-comments">Final comments</h2>
<p>In the next blog <a href="/a-scraper-that-scales-part-ii/">post</a> in the series, I will
go over the implementation details. For those interested, you can find the
current state of the project
<a href="https://github.com/roumail/immoweb-scraper/tree/v1.0.0" target="_blank" rel="noopener">here</a>.</p>

            
<p>
  This post is part of the
  <a href="https://www.rohailtaimour.com/series/building-a-scraper-that-scales/" style="font-weight: bold">Building a Scraper that scales</a>
  series.
</p>


<ol><li><b>Part I: The Motivation to Build a Scraper in Python</b></li></ol>
          </div>
          


 

<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/python/">python</a>
  
  <a class="badge badge-light" href="/tag/web-scraping/">web-scraping</a>
  
</div>


<h3>Share this Article:</h3>

<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=Part%20I%3A%20The%20Motivation%20to%20Build%20a%20Scraper%20in%20Python&amp;body=https%3A%2F%2Fwww.rohailtaimour.com%2Fa-scraper-that-scales-part-i%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fwww.rohailtaimour.com%2Fa-scraper-that-scales-part-i%2F&amp;title=Part&#43;I%3A&#43;The&#43;Motivation&#43;to&#43;Build&#43;a&#43;Scraper&#43;in&#43;Python" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
  </ul>
</div>

 








  
  



 

  
  

 


  
  
  

  

  
  <section id="comments">
    
  
  <script src="https://giscus.app/client.js"
          data-repo="roumail/website-stuff"
          data-repo-id="R_kgDOJIE7Sw"
          data-category="Announcements"
          data-category-id="DIC_kwDOJIE7S84CUy6u"
          data-mapping="pathname"
          data-strict="0"
          data-reactions-enabled="1"
          data-emit-metadata="0"
          data-input-position="top"
          data-theme="preferred_color_scheme"
          data-lang="en"
          data-loading="lazy"
          crossorigin="anonymous"
          async>
  </script>


  </section>
  

  <div style="text-align: center; width: 75%; margin: auto;">
  <p style="font-size: 1.2em; margin-bottom: 1em;">Subscribe to my monthly newsletter</p>
  <form action="https://us21.us21.list-manage.com/subscribe?u=51797cdf15c0dbf7a7f4831b3&amp;id=e897286f6b" method="post" id="mc-embedded-subscribe-form"
    name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div class="form-group" style="margin-bottom: 1em;">
      <input type="email" class="form-control" id="mce-EMAIL" name="EMAIL" aria-describedby="emailHelp"
        placeholder="Enter email" style="margin: auto; width: 75%;" />
    </div>
    <small id="emailHelp" class="form-text text-muted" style="margin-bottom: 1em;">
      Clicking submit takes you to Mailchimp.
    </small>
    <button type="submit" class="btn btn-info">Submit</button>
  </form>
</div>

        </div>
      </main>
    </div>
  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  





  <p class="powered-by">
    Built using Hugo and GitHub Actions.
  </p>
</footer>
    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.3322c0d94f0e691b0b24c63f4c41064b.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js" type="module"></script>


















</body>
</html>
